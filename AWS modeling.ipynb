{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageChops, ImageOps\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_info = pd.read_csv('train_info.csv')\n",
    "all_data_info = pd.read_csv('all_data_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = all_data_info.loc[all_data_info['artist'].isin(['John Singer Sargent', 'Edgar Degas', 'Giovanni Battista Piranesi', 'Claude Monet', 'Raphael Kirchner','Salvador Dali'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df[df['in_train']== True]\n",
    "final_test = df[df['in_train']== False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_jpgs = list(train.new_filename.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2254"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_jpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thumbs = '/home/ec2-user/GA/selected_artists_thumbs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAi2UlEQVR4nG16WZMc2XXePXfLfam9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\nK9Fk0h/v7Pw/BaSXPvC/aGIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7F0FA8261A58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open('/home/ec2-user/GA/selected_artists_thumbs/'+'209.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_array(jpg):\n",
    "    pic = Image.open(thumbs+jpg)\n",
    "    array = np.array(pic.getdata()).reshape(pic.size[0], pic.size[1],3)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_array = []\n",
    "for i in selected_jpgs:\n",
    "    train_array.append(get_array(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2254\n",
      "64\n",
      "64\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(train_array))\n",
    "print(len(train_array[0]))\n",
    "print(len(train_array[0][0]))\n",
    "print(len(train_array[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_array_2d = np.reshape(train_array, (2254,12288))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pull in labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_jpgs_df = pd.DataFrame(selected_jpgs, columns=['jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>95451.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>38925.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>39044.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>65191.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>46569.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            jpg\n",
       "2249  95451.jpg\n",
       "2250  38925.jpg\n",
       "2251  39044.jpg\n",
       "2252  65191.jpg\n",
       "2253  46569.jpg"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_jpgs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12279</th>\n",
       "      <th>12280</th>\n",
       "      <th>12281</th>\n",
       "      <th>12282</th>\n",
       "      <th>12283</th>\n",
       "      <th>12284</th>\n",
       "      <th>12285</th>\n",
       "      <th>12286</th>\n",
       "      <th>12287</th>\n",
       "      <th>jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>95360.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>143</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>148</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>147</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>126</td>\n",
       "      <td>119</td>\n",
       "      <td>112</td>\n",
       "      <td>132</td>\n",
       "      <td>123</td>\n",
       "      <td>121</td>\n",
       "      <td>141</td>\n",
       "      <td>132</td>\n",
       "      <td>49757.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>96147.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>11889.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>856.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...      12279  12280  \\\n",
       "0   99   81   67   97   79   65   95   77   63   96    ...         65     61   \n",
       "1  171  171  143  176  176  148  173  176  147  167    ...        105    126   \n",
       "2  227  227  227  234  234  234  238  238  238  239    ...        235    235   \n",
       "3  232  232  232  232  232  232  232  232  232  231    ...        235    235   \n",
       "4  107  107  107  116  116  116  105  105  105  119    ...        104    104   \n",
       "\n",
       "   12281  12282  12283  12284  12285  12286  12287        jpg  \n",
       "0     52     64     60     51     63     59     50  95360.jpg  \n",
       "1    119    112    132    123    121    141    132  49757.jpg  \n",
       "2    235    220    220    220    222    222    222  96147.jpg  \n",
       "3    235    236    236    236    239    239    239  11889.jpg  \n",
       "4    104    131    131    131    182    182    182    856.jpg  \n",
       "\n",
       "[5 rows x 12289 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df, selected_jpgs_df], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_df = all_data_info[['new_filename', 'artist']]\n",
    "artist_df.columns = ['jpg', 'artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12280</th>\n",
       "      <th>12281</th>\n",
       "      <th>12282</th>\n",
       "      <th>12283</th>\n",
       "      <th>12284</th>\n",
       "      <th>12285</th>\n",
       "      <th>12286</th>\n",
       "      <th>12287</th>\n",
       "      <th>jpg</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>51</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>95360.jpg</td>\n",
       "      <td>Edgar Degas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>143</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>148</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>147</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>119</td>\n",
       "      <td>112</td>\n",
       "      <td>132</td>\n",
       "      <td>123</td>\n",
       "      <td>121</td>\n",
       "      <td>141</td>\n",
       "      <td>132</td>\n",
       "      <td>49757.jpg</td>\n",
       "      <td>Claude Monet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>96147.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>11889.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>856.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  \\\n",
       "0   99   81   67   97   79   65   95   77   63   96   \n",
       "1  171  171  143  176  176  148  173  176  147  167   \n",
       "2  227  227  227  234  234  234  238  238  238  239   \n",
       "3  232  232  232  232  232  232  232  232  232  231   \n",
       "4  107  107  107  116  116  116  105  105  105  119   \n",
       "\n",
       "              ...              12280  12281  12282  12283  12284  12285  \\\n",
       "0             ...                 61     52     64     60     51     63   \n",
       "1             ...                126    119    112    132    123    121   \n",
       "2             ...                235    235    220    220    220    222   \n",
       "3             ...                235    235    236    236    236    239   \n",
       "4             ...                104    104    131    131    131    182   \n",
       "\n",
       "   12286  12287        jpg                      artist  \n",
       "0     59     50  95360.jpg                 Edgar Degas  \n",
       "1    141    132  49757.jpg                Claude Monet  \n",
       "2    222    222  96147.jpg  Giovanni Battista Piranesi  \n",
       "3    239    239  11889.jpg  Giovanni Battista Piranesi  \n",
       "4    182    182    856.jpg  Giovanni Battista Piranesi  \n",
       "\n",
       "[5 rows x 12290 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.merge(train_df, artist_df, on='jpg', how='left')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Giovanni Battista Piranesi    402\n",
       "Edgar Degas                   387\n",
       "Claude Monet                  383\n",
       "John Singer Sargent           377\n",
       "Raphael Kirchner              357\n",
       "Salvador Dali                 348\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.artist.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_df.iloc[:,:-2]\n",
    "y = train_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255.\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1690, 12288)\n",
      "(564, 12288)\n",
      "(1690, 6)\n",
      "(564, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_2d = X_train\n",
    "X_test_2d = X_test\n",
    "\n",
    "y_train_1d = y_train\n",
    "y_test_1d = y_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(X_train_2d.shape)\n",
    "print(X_test_2d.shape)\n",
    "print(y_train_1d.shape)\n",
    "print(y_test_1d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#must reshape to grid for cnn\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.6749 - acc: 0.2864 - val_loss: 1.4454 - val_acc: 0.4007\n",
      "Epoch 2/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.3840 - acc: 0.4698 - val_loss: 1.2022 - val_acc: 0.5656\n",
      "Epoch 3/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.2825 - acc: 0.5249 - val_loss: 1.1386 - val_acc: 0.5957\n",
      "Epoch 4/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.1808 - acc: 0.5598 - val_loss: 1.1097 - val_acc: 0.5993\n",
      "Epoch 5/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.1143 - acc: 0.5899 - val_loss: 1.0842 - val_acc: 0.6046\n",
      "Epoch 6/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.0613 - acc: 0.6083 - val_loss: 1.0885 - val_acc: 0.5975\n",
      "Epoch 7/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.9891 - acc: 0.6408 - val_loss: 1.0014 - val_acc: 0.6330\n",
      "Epoch 8/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.9320 - acc: 0.6467 - val_loss: 1.0950 - val_acc: 0.6099\n",
      "Epoch 9/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.9357 - acc: 0.6533 - val_loss: 0.9444 - val_acc: 0.6560\n",
      "Epoch 10/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.8842 - acc: 0.6698 - val_loss: 1.0088 - val_acc: 0.6330\n",
      "Epoch 11/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.8540 - acc: 0.6805 - val_loss: 0.9568 - val_acc: 0.6507\n",
      "Epoch 12/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.7882 - acc: 0.6941 - val_loss: 0.9580 - val_acc: 0.6507\n",
      "Epoch 13/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.7286 - acc: 0.7337 - val_loss: 1.0424 - val_acc: 0.6277\n",
      "Epoch 14/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.6921 - acc: 0.7544 - val_loss: 1.1584 - val_acc: 0.5887\n",
      "Epoch 15/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.6956 - acc: 0.7337 - val_loss: 1.1696 - val_acc: 0.6099\n",
      "Epoch 16/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.6864 - acc: 0.7450 - val_loss: 1.0874 - val_acc: 0.6259\n",
      "Epoch 17/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.6067 - acc: 0.7669 - val_loss: 1.0956 - val_acc: 0.6365\n",
      "Epoch 18/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.5891 - acc: 0.7751 - val_loss: 1.0677 - val_acc: 0.6312\n",
      "Epoch 19/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.5996 - acc: 0.7864 - val_loss: 1.0853 - val_acc: 0.6383\n",
      "Epoch 20/20\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.5535 - acc: 0.7953 - val_loss: 1.2435 - val_acc: 0.6170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfbbddcef0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((15), (5,5), input_shape=(64, 64, 3), activation='relu'))\n",
    "#15 magnifine glasses, 5X5 is shape of magnifine glass\n",
    "model.add(MaxPool2D(2,2))#2 pixel jump so no overlap on the scan, can use gridsearch to find best pixel slide\n",
    "model.add(Conv2D(30, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2434613281953419, 0.61702127659574468]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 6s 4ms/step - loss: 1.8092 - acc: 0.1675 - val_loss: 1.7830 - val_acc: 0.1773\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.7577 - acc: 0.2089 - val_loss: 1.7361 - val_acc: 0.2961\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.6712 - acc: 0.2988 - val_loss: 1.5860 - val_acc: 0.3475\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.5627 - acc: 0.3491 - val_loss: 1.5139 - val_acc: 0.4539\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.4896 - acc: 0.4024 - val_loss: 1.4373 - val_acc: 0.4929\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4468 - acc: 0.4225 - val_loss: 1.3956 - val_acc: 0.4699\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.4025 - acc: 0.4438 - val_loss: 1.3522 - val_acc: 0.4876\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3711 - acc: 0.4533 - val_loss: 1.2957 - val_acc: 0.5301\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3358 - acc: 0.4769 - val_loss: 1.2884 - val_acc: 0.4929\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2967 - acc: 0.4929 - val_loss: 1.3067 - val_acc: 0.4929\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3529 - acc: 0.4740 - val_loss: 1.2427 - val_acc: 0.5443\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2686 - acc: 0.4982 - val_loss: 1.1936 - val_acc: 0.5177\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2487 - acc: 0.5142 - val_loss: 1.1880 - val_acc: 0.5248\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2706 - acc: 0.5071 - val_loss: 1.2293 - val_acc: 0.4876\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2411 - acc: 0.5207 - val_loss: 1.1661 - val_acc: 0.5408\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2032 - acc: 0.5302 - val_loss: 1.1811 - val_acc: 0.5443\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2225 - acc: 0.5195 - val_loss: 1.1655 - val_acc: 0.5390\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1828 - acc: 0.5183 - val_loss: 1.1650 - val_acc: 0.5461\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1916 - acc: 0.5266 - val_loss: 1.1401 - val_acc: 0.5479\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1748 - acc: 0.5538 - val_loss: 1.1378 - val_acc: 0.5408\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1903 - acc: 0.5355 - val_loss: 1.1968 - val_acc: 0.5408\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1563 - acc: 0.5509 - val_loss: 1.0979 - val_acc: 0.5656\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1495 - acc: 0.5509 - val_loss: 1.1147 - val_acc: 0.5727\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1542 - acc: 0.5396 - val_loss: 1.1606 - val_acc: 0.5248\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1410 - acc: 0.5533 - val_loss: 1.0624 - val_acc: 0.5780\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0939 - acc: 0.5751 - val_loss: 1.1151 - val_acc: 0.5674\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1270 - acc: 0.5556 - val_loss: 1.0489 - val_acc: 0.5975\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0802 - acc: 0.5746 - val_loss: 1.0747 - val_acc: 0.6099\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0880 - acc: 0.5899 - val_loss: 1.0325 - val_acc: 0.6046\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0728 - acc: 0.5905 - val_loss: 1.0668 - val_acc: 0.5816\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0665 - acc: 0.5959 - val_loss: 1.0361 - val_acc: 0.6117\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0446 - acc: 0.6012 - val_loss: 0.9901 - val_acc: 0.5993\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0550 - acc: 0.5899 - val_loss: 1.0223 - val_acc: 0.6383\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0609 - acc: 0.5929 - val_loss: 0.9559 - val_acc: 0.6223\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9977 - acc: 0.6083 - val_loss: 0.9676 - val_acc: 0.6330\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0299 - acc: 0.5988 - val_loss: 1.0358 - val_acc: 0.6082\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0149 - acc: 0.6107 - val_loss: 1.0015 - val_acc: 0.6082\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0100 - acc: 0.6178 - val_loss: 0.9816 - val_acc: 0.6259\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0094 - acc: 0.6059 - val_loss: 0.9985 - val_acc: 0.5993\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0098 - acc: 0.6254 - val_loss: 0.9714 - val_acc: 0.6099\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9680 - acc: 0.6154 - val_loss: 0.9572 - val_acc: 0.6330\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9575 - acc: 0.6302 - val_loss: 0.9979 - val_acc: 0.5940\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9856 - acc: 0.6071 - val_loss: 0.9939 - val_acc: 0.5869\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9639 - acc: 0.6243 - val_loss: 0.9746 - val_acc: 0.6152\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9442 - acc: 0.6183 - val_loss: 0.9509 - val_acc: 0.6188\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9630 - acc: 0.6367 - val_loss: 0.9875 - val_acc: 0.6064\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9744 - acc: 0.6213 - val_loss: 0.9534 - val_acc: 0.6383\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9541 - acc: 0.6331 - val_loss: 0.9992 - val_acc: 0.6082\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9612 - acc: 0.6284 - val_loss: 0.9688 - val_acc: 0.6117\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9521 - acc: 0.6325 - val_loss: 0.9579 - val_acc: 0.6330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21ed093748>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((15), (5,5), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(30, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.84956068378933791, 0.67633136073513145]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.8222 - acc: 0.1710 - val_loss: 1.7908 - val_acc: 0.1862\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.7817 - acc: 0.1876 - val_loss: 1.7834 - val_acc: 0.1560\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.7576 - acc: 0.1982 - val_loss: 1.7546 - val_acc: 0.2181\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.7142 - acc: 0.2396 - val_loss: 1.7116 - val_acc: 0.2518\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.6930 - acc: 0.2793 - val_loss: 1.7177 - val_acc: 0.2571\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.6782 - acc: 0.3189 - val_loss: 1.6659 - val_acc: 0.3174\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.5671 - acc: 0.3621 - val_loss: 1.5430 - val_acc: 0.3706\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4801 - acc: 0.4112 - val_loss: 1.4514 - val_acc: 0.4238\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3957 - acc: 0.4420 - val_loss: 1.4244 - val_acc: 0.4379\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3762 - acc: 0.4598 - val_loss: 1.4644 - val_acc: 0.4096\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3626 - acc: 0.4473 - val_loss: 1.3525 - val_acc: 0.4574\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3239 - acc: 0.4704 - val_loss: 1.2868 - val_acc: 0.4947\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2919 - acc: 0.5024 - val_loss: 1.2812 - val_acc: 0.4965\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2965 - acc: 0.4893 - val_loss: 1.2643 - val_acc: 0.4823\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2506 - acc: 0.5130 - val_loss: 1.2249 - val_acc: 0.5142\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2924 - acc: 0.5112 - val_loss: 1.2431 - val_acc: 0.5301\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2528 - acc: 0.5036 - val_loss: 1.2178 - val_acc: 0.5142\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2381 - acc: 0.5142 - val_loss: 1.1922 - val_acc: 0.5053\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2288 - acc: 0.5278 - val_loss: 1.2383 - val_acc: 0.4947\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2233 - acc: 0.5331 - val_loss: 1.1878 - val_acc: 0.5213\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2138 - acc: 0.5290 - val_loss: 1.2177 - val_acc: 0.5035\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1903 - acc: 0.5367 - val_loss: 1.2234 - val_acc: 0.5035\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1758 - acc: 0.5349 - val_loss: 1.2209 - val_acc: 0.5035\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1615 - acc: 0.5402 - val_loss: 1.2095 - val_acc: 0.5089\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1635 - acc: 0.5592 - val_loss: 1.2030 - val_acc: 0.5195\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1370 - acc: 0.5586 - val_loss: 1.1490 - val_acc: 0.5284\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1191 - acc: 0.5698 - val_loss: 1.1370 - val_acc: 0.5301\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1292 - acc: 0.5574 - val_loss: 1.2685 - val_acc: 0.4592\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1516 - acc: 0.5467 - val_loss: 1.1180 - val_acc: 0.5266\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1063 - acc: 0.5621 - val_loss: 1.1961 - val_acc: 0.5355\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1212 - acc: 0.5698 - val_loss: 1.1368 - val_acc: 0.5071\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2008 - acc: 0.5337 - val_loss: 1.1562 - val_acc: 0.5355\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0988 - acc: 0.5822 - val_loss: 1.1465 - val_acc: 0.5301\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1260 - acc: 0.5692 - val_loss: 1.0937 - val_acc: 0.5479\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0706 - acc: 0.5846 - val_loss: 1.0940 - val_acc: 0.5585\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0544 - acc: 0.5923 - val_loss: 1.1596 - val_acc: 0.5479\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0964 - acc: 0.5751 - val_loss: 1.1498 - val_acc: 0.5160\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1190 - acc: 0.5663 - val_loss: 1.1468 - val_acc: 0.5461\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0406 - acc: 0.6053 - val_loss: 1.0890 - val_acc: 0.5550\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0267 - acc: 0.6000 - val_loss: 1.0548 - val_acc: 0.5798\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0458 - acc: 0.6095 - val_loss: 1.0813 - val_acc: 0.5816\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0418 - acc: 0.6059 - val_loss: 1.0266 - val_acc: 0.6117\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0224 - acc: 0.6006 - val_loss: 1.0189 - val_acc: 0.6294\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0044 - acc: 0.6166 - val_loss: 1.0963 - val_acc: 0.5816\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0284 - acc: 0.6077 - val_loss: 1.0099 - val_acc: 0.6152\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0056 - acc: 0.6213 - val_loss: 0.9785 - val_acc: 0.6170\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0376 - acc: 0.5899 - val_loss: 1.1074 - val_acc: 0.5603\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1053 - acc: 0.5680 - val_loss: 1.1121 - val_acc: 0.5585\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0086 - acc: 0.6160 - val_loss: 1.0783 - val_acc: 0.5780\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9922 - acc: 0.6213 - val_loss: 1.0328 - val_acc: 0.5993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21d9bed0b8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((16), (5,5), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(30, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.92391526579151495, 0.64082840257847806]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2 # L2-regularisation\n",
    "l2_lambda = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 2.0433 - acc: 0.1574 - val_loss: 1.9602 - val_acc: 0.2287\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.9278 - acc: 0.1817 - val_loss: 1.8962 - val_acc: 0.2128\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.8428 - acc: 0.2391 - val_loss: 1.7382 - val_acc: 0.3830\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.7231 - acc: 0.3012 - val_loss: 1.6586 - val_acc: 0.3954\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.6422 - acc: 0.3290 - val_loss: 1.5752 - val_acc: 0.4894\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.5715 - acc: 0.3568 - val_loss: 1.4412 - val_acc: 0.5124\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4934 - acc: 0.4089 - val_loss: 1.3524 - val_acc: 0.5195\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4503 - acc: 0.4325 - val_loss: 1.3239 - val_acc: 0.4858\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3785 - acc: 0.4669 - val_loss: 1.2991 - val_acc: 0.5479\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3756 - acc: 0.4734 - val_loss: 1.2015 - val_acc: 0.5833\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3310 - acc: 0.4893 - val_loss: 1.2422 - val_acc: 0.5550\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3229 - acc: 0.4905 - val_loss: 1.1922 - val_acc: 0.5887\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2883 - acc: 0.5000 - val_loss: 1.1672 - val_acc: 0.5816\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2843 - acc: 0.5225 - val_loss: 1.2276 - val_acc: 0.5638\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2853 - acc: 0.4988 - val_loss: 1.1534 - val_acc: 0.6277\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2680 - acc: 0.5237 - val_loss: 1.1526 - val_acc: 0.6046\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2520 - acc: 0.5320 - val_loss: 1.1596 - val_acc: 0.6152\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2361 - acc: 0.5325 - val_loss: 1.1296 - val_acc: 0.6223\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2289 - acc: 0.5391 - val_loss: 1.1497 - val_acc: 0.6259\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2202 - acc: 0.5467 - val_loss: 1.1628 - val_acc: 0.5603\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2092 - acc: 0.5598 - val_loss: 1.0752 - val_acc: 0.6472\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1640 - acc: 0.5669 - val_loss: 1.0952 - val_acc: 0.6348\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1740 - acc: 0.5633 - val_loss: 1.0817 - val_acc: 0.6454\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1499 - acc: 0.5763 - val_loss: 1.1141 - val_acc: 0.5975\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1617 - acc: 0.5663 - val_loss: 1.0822 - val_acc: 0.5993\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1115 - acc: 0.5970 - val_loss: 1.1149 - val_acc: 0.5833\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1686 - acc: 0.5722 - val_loss: 1.1059 - val_acc: 0.5869\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1150 - acc: 0.5781 - val_loss: 1.0222 - val_acc: 0.6791\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1206 - acc: 0.5858 - val_loss: 1.0796 - val_acc: 0.6223\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1044 - acc: 0.5852 - val_loss: 1.0602 - val_acc: 0.6383\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1058 - acc: 0.5822 - val_loss: 1.0589 - val_acc: 0.6418\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1224 - acc: 0.5953 - val_loss: 1.1791 - val_acc: 0.5745\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1271 - acc: 0.5769 - val_loss: 1.1103 - val_acc: 0.6028\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0771 - acc: 0.6112 - val_loss: 1.0437 - val_acc: 0.6365\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0833 - acc: 0.5953 - val_loss: 1.0661 - val_acc: 0.6330\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0614 - acc: 0.6018 - val_loss: 1.0452 - val_acc: 0.6206\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0751 - acc: 0.6018 - val_loss: 1.0674 - val_acc: 0.6223\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0765 - acc: 0.6047 - val_loss: 1.0118 - val_acc: 0.6525\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0535 - acc: 0.6178 - val_loss: 1.0043 - val_acc: 0.6543\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0428 - acc: 0.6166 - val_loss: 1.0387 - val_acc: 0.6436\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0358 - acc: 0.6148 - val_loss: 1.0438 - val_acc: 0.6206\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0573 - acc: 0.6083 - val_loss: 1.2018 - val_acc: 0.5585\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0494 - acc: 0.6213 - val_loss: 1.0380 - val_acc: 0.6348\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0262 - acc: 0.6183 - val_loss: 1.0566 - val_acc: 0.6170\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0742 - acc: 0.6095 - val_loss: 1.0755 - val_acc: 0.6312\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0333 - acc: 0.6284 - val_loss: 1.0203 - val_acc: 0.6525\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0482 - acc: 0.6195 - val_loss: 1.1011 - val_acc: 0.6223\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0353 - acc: 0.6243 - val_loss: 1.0281 - val_acc: 0.6241\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9927 - acc: 0.6343 - val_loss: 1.0137 - val_acc: 0.6436\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0450 - acc: 0.6201 - val_loss: 1.1548 - val_acc: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff957a4d908>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((16), (5,5), input_shape=(64, 64, 3), kernel_regularizer=l2(.01), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(30, (4,4), kernel_regularizer=l2(.01), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1607800115495039, 0.56213017786748309]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SAVE HERE\n",
    "model.save('model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#beat 70 vs 77 w .001, .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.7453 - acc: 0.2331 - val_loss: 1.5802 - val_acc: 0.4202\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.5193 - acc: 0.3621 - val_loss: 1.4057 - val_acc: 0.4610\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4037 - acc: 0.4503 - val_loss: 1.2584 - val_acc: 0.5018\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3115 - acc: 0.4959 - val_loss: 1.1405 - val_acc: 0.5957\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2178 - acc: 0.5337 - val_loss: 1.0543 - val_acc: 0.6064\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1532 - acc: 0.5538 - val_loss: 1.0380 - val_acc: 0.6294\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0937 - acc: 0.5817 - val_loss: 1.0577 - val_acc: 0.6294\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0998 - acc: 0.5888 - val_loss: 0.9600 - val_acc: 0.6507\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0592 - acc: 0.5988 - val_loss: 0.9653 - val_acc: 0.6560\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9833 - acc: 0.6408 - val_loss: 0.9445 - val_acc: 0.6436\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9798 - acc: 0.6325 - val_loss: 0.9934 - val_acc: 0.6241\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9589 - acc: 0.6438 - val_loss: 0.9637 - val_acc: 0.6312\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9210 - acc: 0.6621 - val_loss: 0.8927 - val_acc: 0.6667\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9270 - acc: 0.6550 - val_loss: 0.9179 - val_acc: 0.6755\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9001 - acc: 0.6734 - val_loss: 0.8986 - val_acc: 0.6738\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8543 - acc: 0.6822 - val_loss: 0.9072 - val_acc: 0.6684\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8838 - acc: 0.6757 - val_loss: 0.9800 - val_acc: 0.6312\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8233 - acc: 0.6929 - val_loss: 0.9297 - val_acc: 0.6543\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8357 - acc: 0.6876 - val_loss: 1.0228 - val_acc: 0.6170\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8107 - acc: 0.7118 - val_loss: 0.8541 - val_acc: 0.6879\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7541 - acc: 0.7237 - val_loss: 0.9825 - val_acc: 0.6312\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7445 - acc: 0.7290 - val_loss: 0.9572 - val_acc: 0.6418\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7415 - acc: 0.7278 - val_loss: 0.8547 - val_acc: 0.6826\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6533 - acc: 0.7686 - val_loss: 0.9248 - val_acc: 0.6738\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6721 - acc: 0.7503 - val_loss: 0.9243 - val_acc: 0.6613\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6466 - acc: 0.7521 - val_loss: 0.8782 - val_acc: 0.6968\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5915 - acc: 0.7923 - val_loss: 0.9387 - val_acc: 0.6738\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6195 - acc: 0.7751 - val_loss: 0.9378 - val_acc: 0.6738\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5923 - acc: 0.7811 - val_loss: 0.9523 - val_acc: 0.6702\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5343 - acc: 0.7988 - val_loss: 1.0162 - val_acc: 0.6702\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5179 - acc: 0.8107 - val_loss: 1.0364 - val_acc: 0.6472\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5115 - acc: 0.8142 - val_loss: 0.9771 - val_acc: 0.6684\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4457 - acc: 0.8515 - val_loss: 1.0704 - val_acc: 0.6596\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4264 - acc: 0.8402 - val_loss: 1.0660 - val_acc: 0.6543\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4140 - acc: 0.8509 - val_loss: 1.2164 - val_acc: 0.6454\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4411 - acc: 0.8426 - val_loss: 1.0697 - val_acc: 0.6613\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.3713 - acc: 0.8805 - val_loss: 1.1129 - val_acc: 0.6649\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.3508 - acc: 0.8728 - val_loss: 1.1705 - val_acc: 0.6596\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.3620 - acc: 0.8769 - val_loss: 1.2550 - val_acc: 0.6259\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.3353 - acc: 0.8799 - val_loss: 1.2228 - val_acc: 0.6525\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.2856 - acc: 0.8976 - val_loss: 1.1949 - val_acc: 0.6720\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.2581 - acc: 0.9148 - val_loss: 1.4217 - val_acc: 0.6348\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.2617 - acc: 0.9118 - val_loss: 1.3974 - val_acc: 0.6436\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.2216 - acc: 0.9290 - val_loss: 1.3975 - val_acc: 0.6507\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.2201 - acc: 0.9249 - val_loss: 1.3328 - val_acc: 0.6684\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.1974 - acc: 0.9391 - val_loss: 1.3248 - val_acc: 0.6720\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.1700 - acc: 0.9479 - val_loss: 1.4930 - val_acc: 0.6543\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.2081 - acc: 0.9349 - val_loss: 1.3084 - val_acc: 0.6667\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.1958 - acc: 0.9284 - val_loss: 1.4404 - val_acc: 0.6613\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.1908 - acc: 0.9355 - val_loss: 1.5340 - val_acc: 0.6489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45653188d0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((15), (5,5), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPool2D(4,4)) \n",
    "model.add(Conv2D(20, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.8101 - acc: 0.1941 - val_loss: 1.7821 - val_acc: 0.1773\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.7531 - acc: 0.2426 - val_loss: 1.7496 - val_acc: 0.2801\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.6459 - acc: 0.2988 - val_loss: 1.6797 - val_acc: 0.3032\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.5485 - acc: 0.3698 - val_loss: 1.5185 - val_acc: 0.5319\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4751 - acc: 0.3964 - val_loss: 1.4013 - val_acc: 0.5390\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4344 - acc: 0.4231 - val_loss: 1.3643 - val_acc: 0.5691\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3863 - acc: 0.4355 - val_loss: 1.3217 - val_acc: 0.5656\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3958 - acc: 0.4509 - val_loss: 1.3864 - val_acc: 0.5124\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3050 - acc: 0.4858 - val_loss: 1.2749 - val_acc: 0.5337\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2827 - acc: 0.4911 - val_loss: 1.2841 - val_acc: 0.5443\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2529 - acc: 0.5065 - val_loss: 1.2278 - val_acc: 0.5656\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2298 - acc: 0.5130 - val_loss: 1.2103 - val_acc: 0.5674\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2046 - acc: 0.5402 - val_loss: 1.2536 - val_acc: 0.4840\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1756 - acc: 0.5521 - val_loss: 1.2358 - val_acc: 0.5461\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1529 - acc: 0.5574 - val_loss: 1.1461 - val_acc: 0.5603\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0911 - acc: 0.5728 - val_loss: 1.1505 - val_acc: 0.5851\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0927 - acc: 0.5793 - val_loss: 1.1416 - val_acc: 0.5479\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0945 - acc: 0.5822 - val_loss: 1.2236 - val_acc: 0.5603\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1034 - acc: 0.5692 - val_loss: 1.0556 - val_acc: 0.6064\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0831 - acc: 0.5799 - val_loss: 1.0724 - val_acc: 0.6082\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0729 - acc: 0.5929 - val_loss: 1.0927 - val_acc: 0.6188\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9947 - acc: 0.6166 - val_loss: 1.0584 - val_acc: 0.5727\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0213 - acc: 0.6083 - val_loss: 1.1349 - val_acc: 0.5727\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0110 - acc: 0.6118 - val_loss: 1.0421 - val_acc: 0.6064\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9620 - acc: 0.6284 - val_loss: 1.2399 - val_acc: 0.5372\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9994 - acc: 0.5947 - val_loss: 1.1945 - val_acc: 0.5550\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9802 - acc: 0.6178 - val_loss: 1.1366 - val_acc: 0.5887\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9667 - acc: 0.6432 - val_loss: 0.9694 - val_acc: 0.6472\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9561 - acc: 0.6231 - val_loss: 1.1073 - val_acc: 0.5957\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9109 - acc: 0.6562 - val_loss: 0.9879 - val_acc: 0.6170\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8952 - acc: 0.6651 - val_loss: 1.0675 - val_acc: 0.6188\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8989 - acc: 0.6615 - val_loss: 1.1128 - val_acc: 0.5798\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8947 - acc: 0.6580 - val_loss: 0.9383 - val_acc: 0.6667\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8856 - acc: 0.6604 - val_loss: 1.1633 - val_acc: 0.5851\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8925 - acc: 0.6615 - val_loss: 1.0693 - val_acc: 0.6046\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8487 - acc: 0.6746 - val_loss: 1.0897 - val_acc: 0.6223\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8517 - acc: 0.6751 - val_loss: 1.1432 - val_acc: 0.6241\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8452 - acc: 0.6657 - val_loss: 1.2333 - val_acc: 0.5816\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8695 - acc: 0.6834 - val_loss: 0.9359 - val_acc: 0.6649\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8264 - acc: 0.6888 - val_loss: 1.1434 - val_acc: 0.5993\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8271 - acc: 0.6817 - val_loss: 1.0389 - val_acc: 0.6135\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8167 - acc: 0.6905 - val_loss: 1.0282 - val_acc: 0.6259\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7932 - acc: 0.7047 - val_loss: 1.0341 - val_acc: 0.6383\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7610 - acc: 0.7101 - val_loss: 1.0850 - val_acc: 0.6330\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8021 - acc: 0.6822 - val_loss: 1.0290 - val_acc: 0.6046\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7942 - acc: 0.6917 - val_loss: 1.1471 - val_acc: 0.6135\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7678 - acc: 0.7006 - val_loss: 1.0219 - val_acc: 0.6507\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7548 - acc: 0.7249 - val_loss: 0.9863 - val_acc: 0.6613\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7412 - acc: 0.7254 - val_loss: 1.0233 - val_acc: 0.6277\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.7434 - acc: 0.7195 - val_loss: 1.0220 - val_acc: 0.6223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff95a9e6be0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((15), (5,5), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPool2D(4,4)) \n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(20, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0219816823377676, 0.62234042553191493]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_kirchner_piranesi = all_data_info.loc[all_data_info['artist'].isin(['Giovanni Battista Piranesi', 'Claude Monet'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_kp = df_kirchner_piranesi[df_kirchner_piranesi['in_train']== True]\n",
    "final_test_kp = df_kirchner_piranesi[df_kirchner_piranesi['in_train']== False]\n",
    "\n",
    "kirchner_piranesi_jpgs = list(final_test_kp.new_filename.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_kp = train_df[train_df['artist'].isin(['Giovanni Battista Piranesi', 'Raphael Kirchner'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12280</th>\n",
       "      <th>12281</th>\n",
       "      <th>12282</th>\n",
       "      <th>12283</th>\n",
       "      <th>12284</th>\n",
       "      <th>12285</th>\n",
       "      <th>12286</th>\n",
       "      <th>12287</th>\n",
       "      <th>jpg</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>96147.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>11889.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>856.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>67325.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>94943.jpg</td>\n",
       "      <td>Giovanni Battista Piranesi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  \\\n",
       "2  227  227  227  234  234  234  238  238  238  239   \n",
       "3  232  232  232  232  232  232  232  232  232  231   \n",
       "4  107  107  107  116  116  116  105  105  105  119   \n",
       "5  202  202  202  206  206  206  209  209  209  209   \n",
       "8  147  147  147  172  172  172  166  166  166  159   \n",
       "\n",
       "              ...              12280  12281  12282  12283  12284  12285  \\\n",
       "2             ...                235    235    220    220    220    222   \n",
       "3             ...                235    235    236    236    236    239   \n",
       "4             ...                104    104    131    131    131    182   \n",
       "5             ...                181    181    192    192    192    187   \n",
       "8             ...                178    178    181    181    181    153   \n",
       "\n",
       "   12286  12287        jpg                      artist  \n",
       "2    222    222  96147.jpg  Giovanni Battista Piranesi  \n",
       "3    239    239  11889.jpg  Giovanni Battista Piranesi  \n",
       "4    182    182    856.jpg  Giovanni Battista Piranesi  \n",
       "5    187    187  67325.jpg  Giovanni Battista Piranesi  \n",
       "8    153    153  94943.jpg  Giovanni Battista Piranesi  \n",
       "\n",
       "[5 rows x 12290 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_kp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_df_kp.iloc[:,:-2]\n",
    "y = train_df_kp.artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 64, 64, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 569 samples, validate on 190 samples\n",
      "Epoch 1/50\n",
      "569/569 [==============================] - 2s 4ms/step - loss: 7.5860 - acc: 0.5167 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 2/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.0951 - acc: 0.4974 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 3/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2151 - acc: 0.4903 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 4/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2873 - acc: 0.4833 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 5/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3815 - acc: 0.4798 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 6/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 7.8534 - acc: 0.5114 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 7/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.1649 - acc: 0.4921 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 8/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.4577 - acc: 0.4710 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 9/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.6114 - acc: 0.4657 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 10/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2029 - acc: 0.4868 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 11/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3877 - acc: 0.4780 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 12/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.4755 - acc: 0.4728 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 13/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 7.7850 - acc: 0.5167 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 14/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2148 - acc: 0.4903 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 15/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2151 - acc: 0.4903 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 16/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3280 - acc: 0.4833 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 17/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.1392 - acc: 0.4938 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 18/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2220 - acc: 0.4886 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 19/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.1995 - acc: 0.4903 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 20/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.0734 - acc: 0.4991 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 21/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3114 - acc: 0.4833 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 22/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.4424 - acc: 0.4763 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 23/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.1676 - acc: 0.4921 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 24/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.1415 - acc: 0.4921 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 25/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2998 - acc: 0.4851 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 26/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3255 - acc: 0.4833 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 27/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2998 - acc: 0.4851 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 28/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2715 - acc: 0.4868 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 29/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2148 - acc: 0.4903 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 30/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.4340 - acc: 0.4763 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 31/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3295 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 32/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3565 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 33/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2444 - acc: 0.4868 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 34/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2998 - acc: 0.4851 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 35/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.2432 - acc: 0.4886 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 36/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3487 - acc: 0.4798 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 37/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3848 - acc: 0.4798 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 38/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3283 - acc: 0.4833 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 39/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3565 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 40/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3848 - acc: 0.4798 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 41/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3282 - acc: 0.4833 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 42/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3577 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 43/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3577 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 44/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3294 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 45/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.4415 - acc: 0.4763 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 46/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3565 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 47/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3567 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 48/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3282 - acc: 0.4833 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 49/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3849 - acc: 0.4798 - val_loss: 9.0770 - val_acc: 0.4368\n",
      "Epoch 50/50\n",
      "569/569 [==============================] - 2s 3ms/step - loss: 8.3565 - acc: 0.4815 - val_loss: 9.0770 - val_acc: 0.4368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8a48cbcf8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((15), (5,5), input_shape=(64, 64, 3), activation='relu'))\n",
    "model.add(MaxPool2D(4,4)) \n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(20, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.7856 - acc: 0.1822 - val_loss: 1.7660 - val_acc: 0.2855\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.7073 - acc: 0.2947 - val_loss: 1.6916 - val_acc: 0.3209\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.6290 - acc: 0.3302 - val_loss: 1.6248 - val_acc: 0.3404\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.5719 - acc: 0.3586 - val_loss: 1.5778 - val_acc: 0.3741\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.5137 - acc: 0.3935 - val_loss: 1.5179 - val_acc: 0.4007\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4707 - acc: 0.4041 - val_loss: 1.4103 - val_acc: 0.4415\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4139 - acc: 0.4183 - val_loss: 1.3508 - val_acc: 0.4663\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3879 - acc: 0.4521 - val_loss: 1.4396 - val_acc: 0.4344\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3459 - acc: 0.4686 - val_loss: 1.2807 - val_acc: 0.5248\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3233 - acc: 0.4822 - val_loss: 1.4252 - val_acc: 0.4255\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3423 - acc: 0.4722 - val_loss: 1.2188 - val_acc: 0.5301\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2555 - acc: 0.4964 - val_loss: 1.2202 - val_acc: 0.5461\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2687 - acc: 0.4911 - val_loss: 1.2238 - val_acc: 0.5355\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2394 - acc: 0.5118 - val_loss: 1.2542 - val_acc: 0.5195\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2103 - acc: 0.5189 - val_loss: 1.1399 - val_acc: 0.5514\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2337 - acc: 0.5172 - val_loss: 1.1928 - val_acc: 0.5443\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2071 - acc: 0.5290 - val_loss: 1.1512 - val_acc: 0.5550\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2064 - acc: 0.5154 - val_loss: 1.2163 - val_acc: 0.5408\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1652 - acc: 0.5479 - val_loss: 1.0915 - val_acc: 0.5674\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1704 - acc: 0.5444 - val_loss: 1.0718 - val_acc: 0.5656\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1046 - acc: 0.5609 - val_loss: 1.0842 - val_acc: 0.5603\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1058 - acc: 0.5515 - val_loss: 1.0939 - val_acc: 0.5585\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0902 - acc: 0.5852 - val_loss: 1.0600 - val_acc: 0.5691\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0729 - acc: 0.5840 - val_loss: 1.0063 - val_acc: 0.5922\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0726 - acc: 0.5763 - val_loss: 1.0526 - val_acc: 0.5993\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0684 - acc: 0.5805 - val_loss: 1.0785 - val_acc: 0.5816\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0199 - acc: 0.6071 - val_loss: 0.9783 - val_acc: 0.6082\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0605 - acc: 0.5923 - val_loss: 1.0699 - val_acc: 0.5975\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0301 - acc: 0.5870 - val_loss: 1.0306 - val_acc: 0.5922\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9911 - acc: 0.6254 - val_loss: 0.9856 - val_acc: 0.6206\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9827 - acc: 0.6142 - val_loss: 1.0532 - val_acc: 0.6170\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9937 - acc: 0.6160 - val_loss: 1.0257 - val_acc: 0.6064\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9551 - acc: 0.6290 - val_loss: 0.9577 - val_acc: 0.6401\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9817 - acc: 0.6178 - val_loss: 0.9920 - val_acc: 0.6241\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9973 - acc: 0.6195 - val_loss: 0.9599 - val_acc: 0.6117\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9256 - acc: 0.6373 - val_loss: 0.9244 - val_acc: 0.6401\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9199 - acc: 0.6414 - val_loss: 1.0076 - val_acc: 0.6241\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9016 - acc: 0.6509 - val_loss: 0.9456 - val_acc: 0.6454\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9505 - acc: 0.6408 - val_loss: 0.9723 - val_acc: 0.6418\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8970 - acc: 0.6408 - val_loss: 0.9794 - val_acc: 0.6436\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8904 - acc: 0.6521 - val_loss: 0.9896 - val_acc: 0.6330\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8719 - acc: 0.6615 - val_loss: 0.9378 - val_acc: 0.6596\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8921 - acc: 0.6556 - val_loss: 0.9709 - val_acc: 0.6330\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8493 - acc: 0.6728 - val_loss: 0.9175 - val_acc: 0.6525\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8476 - acc: 0.6716 - val_loss: 0.9718 - val_acc: 0.6472\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8557 - acc: 0.6680 - val_loss: 0.9345 - val_acc: 0.6401\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8253 - acc: 0.6781 - val_loss: 0.9512 - val_acc: 0.6472\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7935 - acc: 0.6994 - val_loss: 0.9130 - val_acc: 0.6738\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7982 - acc: 0.6923 - val_loss: 0.9227 - val_acc: 0.6684\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8335 - acc: 0.6941 - val_loss: 0.9665 - val_acc: 0.6472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f489e053f98>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((15), (5,5), input_shape=(64, 64, 3), kernel_regularizer=l2(.001), activation='relu'))\n",
    "model.add(MaxPool2D(4,4)) \n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(20, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 0s 940us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.3135440424868943, 0.48421052757062411]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 6s 4ms/step - loss: 1.7966 - acc: 0.1876 - val_loss: 1.7872 - val_acc: 0.1897\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.7491 - acc: 0.2479 - val_loss: 1.6909 - val_acc: 0.2890\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.6639 - acc: 0.3036 - val_loss: 1.6013 - val_acc: 0.4096\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.5931 - acc: 0.3550 - val_loss: 1.5155 - val_acc: 0.3865\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.5142 - acc: 0.3935 - val_loss: 1.5315 - val_acc: 0.3599\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.4483 - acc: 0.4243 - val_loss: 1.3384 - val_acc: 0.4770\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3849 - acc: 0.4408 - val_loss: 1.3254 - val_acc: 0.5018\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3500 - acc: 0.4645 - val_loss: 1.2665 - val_acc: 0.5035\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3296 - acc: 0.4805 - val_loss: 1.2224 - val_acc: 0.5035\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3144 - acc: 0.4870 - val_loss: 1.1876 - val_acc: 0.5656\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2576 - acc: 0.5160 - val_loss: 1.2331 - val_acc: 0.5284\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3398 - acc: 0.4657 - val_loss: 1.2764 - val_acc: 0.4982\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.3035 - acc: 0.5018 - val_loss: 1.1926 - val_acc: 0.5727\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2280 - acc: 0.5302 - val_loss: 1.1579 - val_acc: 0.5479\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.2088 - acc: 0.5467 - val_loss: 1.0842 - val_acc: 0.5816\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1754 - acc: 0.5515 - val_loss: 1.1268 - val_acc: 0.5833\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1570 - acc: 0.5592 - val_loss: 1.2117 - val_acc: 0.5550\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1553 - acc: 0.5609 - val_loss: 1.0581 - val_acc: 0.5993\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1017 - acc: 0.5716 - val_loss: 1.0303 - val_acc: 0.6117\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1252 - acc: 0.5604 - val_loss: 1.0626 - val_acc: 0.5887\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1384 - acc: 0.5580 - val_loss: 1.0270 - val_acc: 0.6241\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1049 - acc: 0.5840 - val_loss: 1.0635 - val_acc: 0.5691\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.1000 - acc: 0.5828 - val_loss: 1.0179 - val_acc: 0.6188\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0608 - acc: 0.5935 - val_loss: 1.0228 - val_acc: 0.6046\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0629 - acc: 0.5858 - val_loss: 1.0331 - val_acc: 0.5940\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0435 - acc: 0.5947 - val_loss: 0.9647 - val_acc: 0.6365\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0546 - acc: 0.6112 - val_loss: 1.0295 - val_acc: 0.5833\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9990 - acc: 0.6254 - val_loss: 0.9581 - val_acc: 0.6241\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0820 - acc: 0.5799 - val_loss: 0.9779 - val_acc: 0.6082\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0300 - acc: 0.6059 - val_loss: 0.9583 - val_acc: 0.6223\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9918 - acc: 0.6178 - val_loss: 0.9651 - val_acc: 0.6294\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0022 - acc: 0.6178 - val_loss: 0.9491 - val_acc: 0.6259\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.0002 - acc: 0.6172 - val_loss: 0.9356 - val_acc: 0.6223\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9635 - acc: 0.6207 - val_loss: 0.9494 - val_acc: 0.6365\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9738 - acc: 0.6178 - val_loss: 0.9556 - val_acc: 0.6241\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9960 - acc: 0.6101 - val_loss: 1.0561 - val_acc: 0.5887\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9619 - acc: 0.6302 - val_loss: 1.0429 - val_acc: 0.6028\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9242 - acc: 0.6391 - val_loss: 1.0535 - val_acc: 0.6011\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9358 - acc: 0.6349 - val_loss: 0.9973 - val_acc: 0.6028\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9218 - acc: 0.6479 - val_loss: 1.0017 - val_acc: 0.6117\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9317 - acc: 0.6509 - val_loss: 0.9405 - val_acc: 0.6294\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8986 - acc: 0.6438 - val_loss: 1.0859 - val_acc: 0.5833\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9108 - acc: 0.6568 - val_loss: 0.9583 - val_acc: 0.6277\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9184 - acc: 0.6491 - val_loss: 1.0516 - val_acc: 0.5993\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9520 - acc: 0.6497 - val_loss: 0.9698 - val_acc: 0.6206\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8798 - acc: 0.6698 - val_loss: 0.9189 - val_acc: 0.6259\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.9003 - acc: 0.6615 - val_loss: 0.9880 - val_acc: 0.6046\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8959 - acc: 0.6533 - val_loss: 0.9165 - val_acc: 0.6206\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8660 - acc: 0.6728 - val_loss: 0.9790 - val_acc: 0.6401\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 0.8749 - acc: 0.6621 - val_loss: 1.0122 - val_acc: 0.6223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f489c8fdd30>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((15), (5,5), input_shape=(64, 64, 3), kernel_regularizer=l2(.001), activation='relu'))\n",
    "model.add(MaxPool2D(4,4)) \n",
    "model.add(Dropout(.5))\n",
    "model.add(Conv2D(20, (4,4), kernel_regularizer=l2(.0001), activation='relu'))\n",
    "model.add(Conv2D(15, (4,4), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.012179359053889, 0.62234042510918697]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/50\n",
      "1690/1690 [==============================] - 6s 3ms/step - loss: 1.8747 - acc: 0.2521 - val_loss: 1.6329 - val_acc: 0.4539\n",
      "Epoch 2/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.6283 - acc: 0.3675 - val_loss: 1.4099 - val_acc: 0.4929\n",
      "Epoch 3/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.4529 - acc: 0.4533 - val_loss: 1.3153 - val_acc: 0.5230\n",
      "Epoch 4/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3554 - acc: 0.5136 - val_loss: 1.2392 - val_acc: 0.5479\n",
      "Epoch 5/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.3019 - acc: 0.5166 - val_loss: 1.2064 - val_acc: 0.5798\n",
      "Epoch 6/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.2348 - acc: 0.5533 - val_loss: 1.0634 - val_acc: 0.6259\n",
      "Epoch 7/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1767 - acc: 0.5751 - val_loss: 1.1003 - val_acc: 0.6135\n",
      "Epoch 8/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1534 - acc: 0.5852 - val_loss: 1.1567 - val_acc: 0.5922\n",
      "Epoch 9/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.1415 - acc: 0.5822 - val_loss: 1.0441 - val_acc: 0.6259\n",
      "Epoch 10/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0891 - acc: 0.6012 - val_loss: 0.9622 - val_acc: 0.6720\n",
      "Epoch 11/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0890 - acc: 0.6107 - val_loss: 1.0415 - val_acc: 0.6241\n",
      "Epoch 12/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0516 - acc: 0.6189 - val_loss: 0.9694 - val_acc: 0.6738\n",
      "Epoch 13/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 1.0473 - acc: 0.6225 - val_loss: 0.9611 - val_acc: 0.6809\n",
      "Epoch 14/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9582 - acc: 0.6574 - val_loss: 0.9385 - val_acc: 0.6773\n",
      "Epoch 15/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9323 - acc: 0.6627 - val_loss: 0.9492 - val_acc: 0.6809\n",
      "Epoch 16/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9248 - acc: 0.6686 - val_loss: 0.9019 - val_acc: 0.6809\n",
      "Epoch 17/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9040 - acc: 0.6746 - val_loss: 0.9181 - val_acc: 0.6915\n",
      "Epoch 18/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9113 - acc: 0.6680 - val_loss: 0.9280 - val_acc: 0.6915\n",
      "Epoch 19/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.9129 - acc: 0.6692 - val_loss: 0.9378 - val_acc: 0.6879\n",
      "Epoch 20/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8798 - acc: 0.7018 - val_loss: 0.8974 - val_acc: 0.6826\n",
      "Epoch 21/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8773 - acc: 0.6893 - val_loss: 0.9809 - val_acc: 0.6631\n",
      "Epoch 22/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8656 - acc: 0.6917 - val_loss: 0.9617 - val_acc: 0.6791\n",
      "Epoch 23/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8566 - acc: 0.7018 - val_loss: 0.9341 - val_acc: 0.6826\n",
      "Epoch 24/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7862 - acc: 0.7278 - val_loss: 0.9048 - val_acc: 0.7039\n",
      "Epoch 25/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7448 - acc: 0.7574 - val_loss: 0.9687 - val_acc: 0.6915\n",
      "Epoch 26/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.8190 - acc: 0.7172 - val_loss: 0.9322 - val_acc: 0.6720\n",
      "Epoch 27/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7327 - acc: 0.7497 - val_loss: 0.9067 - val_acc: 0.7039\n",
      "Epoch 28/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7415 - acc: 0.7467 - val_loss: 0.9611 - val_acc: 0.6649\n",
      "Epoch 29/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.7253 - acc: 0.7586 - val_loss: 0.9184 - val_acc: 0.7021\n",
      "Epoch 30/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6988 - acc: 0.7609 - val_loss: 1.0035 - val_acc: 0.6791\n",
      "Epoch 31/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6693 - acc: 0.7959 - val_loss: 0.9779 - val_acc: 0.6933\n",
      "Epoch 32/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6504 - acc: 0.7923 - val_loss: 1.0137 - val_acc: 0.6649\n",
      "Epoch 33/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6414 - acc: 0.7876 - val_loss: 1.0138 - val_acc: 0.6720\n",
      "Epoch 34/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5903 - acc: 0.8178 - val_loss: 0.9910 - val_acc: 0.6809\n",
      "Epoch 35/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5744 - acc: 0.8296 - val_loss: 1.0270 - val_acc: 0.6826\n",
      "Epoch 36/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.6441 - acc: 0.7882 - val_loss: 0.9811 - val_acc: 0.6826\n",
      "Epoch 37/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5762 - acc: 0.8195 - val_loss: 1.0449 - val_acc: 0.6862\n",
      "Epoch 38/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5713 - acc: 0.8213 - val_loss: 1.1067 - val_acc: 0.6578\n",
      "Epoch 39/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5209 - acc: 0.8349 - val_loss: 1.0452 - val_acc: 0.6649\n",
      "Epoch 40/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.5039 - acc: 0.8450 - val_loss: 1.0337 - val_acc: 0.6933\n",
      "Epoch 41/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4803 - acc: 0.8627 - val_loss: 1.0912 - val_acc: 0.7004\n",
      "Epoch 42/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4849 - acc: 0.8686 - val_loss: 1.1086 - val_acc: 0.6950\n",
      "Epoch 43/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4647 - acc: 0.8686 - val_loss: 1.0773 - val_acc: 0.6915\n",
      "Epoch 44/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4133 - acc: 0.8893 - val_loss: 1.1928 - val_acc: 0.6702\n",
      "Epoch 45/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4067 - acc: 0.8917 - val_loss: 1.2199 - val_acc: 0.6578\n",
      "Epoch 46/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4219 - acc: 0.8840 - val_loss: 1.3211 - val_acc: 0.6454\n",
      "Epoch 47/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.4356 - acc: 0.8799 - val_loss: 1.2075 - val_acc: 0.6915\n",
      "Epoch 48/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.3971 - acc: 0.8923 - val_loss: 1.3835 - val_acc: 0.6560\n",
      "Epoch 49/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.3611 - acc: 0.9118 - val_loss: 1.2134 - val_acc: 0.6915\n",
      "Epoch 50/50\n",
      "1690/1690 [==============================] - 5s 3ms/step - loss: 0.3604 - acc: 0.9101 - val_loss: 1.2949 - val_acc: 0.6773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff947d8a7f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D((16), (5,5), input_shape=(64, 64, 3), kernel_regularizer=l2(.001), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Conv2D(30, (4,4), kernel_regularizer=l2(.01), activation='relu'))\n",
    "model.add(MaxPool2D(4,4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.7476 - acc: 0.2515 - val_loss: 1.6169 - val_acc: 0.3617\n",
      "Epoch 2/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.4557 - acc: 0.4278 - val_loss: 1.3922 - val_acc: 0.4291\n",
      "Epoch 3/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.2875 - acc: 0.4929 - val_loss: 1.2746 - val_acc: 0.5124\n",
      "Epoch 4/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.2089 - acc: 0.5219 - val_loss: 1.1724 - val_acc: 0.5160\n",
      "Epoch 5/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.1570 - acc: 0.5503 - val_loss: 1.1457 - val_acc: 0.5301\n",
      "Epoch 6/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.1397 - acc: 0.5621 - val_loss: 1.1288 - val_acc: 0.5691\n",
      "Epoch 7/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.1157 - acc: 0.5775 - val_loss: 1.1311 - val_acc: 0.5514\n",
      "Epoch 8/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0685 - acc: 0.5888 - val_loss: 1.2092 - val_acc: 0.5496\n",
      "Epoch 9/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0491 - acc: 0.5935 - val_loss: 1.0735 - val_acc: 0.5869\n",
      "Epoch 10/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0011 - acc: 0.6160 - val_loss: 1.0895 - val_acc: 0.5869\n",
      "Epoch 11/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9827 - acc: 0.6402 - val_loss: 1.0744 - val_acc: 0.5851\n",
      "Epoch 12/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0163 - acc: 0.6195 - val_loss: 1.0410 - val_acc: 0.5833\n",
      "Epoch 13/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9467 - acc: 0.6497 - val_loss: 1.0514 - val_acc: 0.5922\n",
      "Epoch 14/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9587 - acc: 0.6467 - val_loss: 1.0807 - val_acc: 0.5816\n",
      "Epoch 15/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9320 - acc: 0.6408 - val_loss: 1.1440 - val_acc: 0.5638\n",
      "Epoch 16/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9161 - acc: 0.6402 - val_loss: 1.0196 - val_acc: 0.6206\n",
      "Epoch 17/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9239 - acc: 0.6621 - val_loss: 1.0722 - val_acc: 0.5709\n",
      "Epoch 18/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.8880 - acc: 0.6544 - val_loss: 1.0688 - val_acc: 0.5851\n",
      "Epoch 19/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.8273 - acc: 0.6840 - val_loss: 1.0057 - val_acc: 0.6223\n",
      "Epoch 20/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.8406 - acc: 0.6893 - val_loss: 1.0876 - val_acc: 0.5727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f454703bf98>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(12, kernel_size=(4,4), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(Conv2D(20, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D((4,4)))\n",
    "model.add(Conv2D(20, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D((4,4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1690 samples, validate on 564 samples\n",
      "Epoch 1/20\n",
      "1690/1690 [==============================] - 11s 7ms/step - loss: 1.7919 - acc: 0.1864 - val_loss: 1.7834 - val_acc: 0.1543\n",
      "Epoch 2/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.6643 - acc: 0.2988 - val_loss: 1.4966 - val_acc: 0.3528\n",
      "Epoch 3/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.4786 - acc: 0.3497 - val_loss: 1.4324 - val_acc: 0.3617\n",
      "Epoch 4/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.4380 - acc: 0.3692 - val_loss: 1.4062 - val_acc: 0.4344\n",
      "Epoch 5/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.3745 - acc: 0.4225 - val_loss: 1.3941 - val_acc: 0.4131\n",
      "Epoch 6/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.3191 - acc: 0.4533 - val_loss: 1.2973 - val_acc: 0.4433\n",
      "Epoch 7/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.3198 - acc: 0.4527 - val_loss: 1.2407 - val_acc: 0.4965\n",
      "Epoch 8/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.2412 - acc: 0.5000 - val_loss: 1.2491 - val_acc: 0.5142\n",
      "Epoch 9/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.1805 - acc: 0.5243 - val_loss: 1.1536 - val_acc: 0.5603\n",
      "Epoch 10/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.1648 - acc: 0.5586 - val_loss: 1.1419 - val_acc: 0.5709\n",
      "Epoch 11/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.1681 - acc: 0.5325 - val_loss: 1.1143 - val_acc: 0.5691\n",
      "Epoch 12/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0969 - acc: 0.5680 - val_loss: 1.1104 - val_acc: 0.5780\n",
      "Epoch 13/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0804 - acc: 0.5651 - val_loss: 1.1011 - val_acc: 0.5816\n",
      "Epoch 14/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.1200 - acc: 0.5604 - val_loss: 1.1116 - val_acc: 0.5603\n",
      "Epoch 15/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0652 - acc: 0.5817 - val_loss: 1.2214 - val_acc: 0.5408\n",
      "Epoch 16/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0487 - acc: 0.5834 - val_loss: 1.0499 - val_acc: 0.5816\n",
      "Epoch 17/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0262 - acc: 0.6000 - val_loss: 1.0402 - val_acc: 0.5780\n",
      "Epoch 18/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 1.0137 - acc: 0.6006 - val_loss: 1.0293 - val_acc: 0.5957\n",
      "Epoch 19/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9881 - acc: 0.6083 - val_loss: 1.0480 - val_acc: 0.6117\n",
      "Epoch 20/20\n",
      "1690/1690 [==============================] - 10s 6ms/step - loss: 0.9746 - acc: 0.6118 - val_loss: 1.0541 - val_acc: 0.5957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f454324ffd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(12, kernel_size=(4,4), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(Conv2D(20, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D((4,4)))\n",
    "model.add(Conv2D(25, kernel_size=(5,5), activation='relu'))\n",
    "model.add(Conv2D(20, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D((4,4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_funk(input_shape=(64,64,3), layer_one_neurons=25, layer_two_neurons=20, \n",
    "               batch_size=50, kernel_size_one=(4,4), \n",
    "               kernel_size_two=(4,4)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(layer_one_neurons, kernel_size=kernel_size_one, input_shape=(64,64,3), activation='relu'))\n",
    "    model.add(Conv2D(layer_two_neurons, kernel_size=kernel_size_two, activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(15, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1126/1126 [==============================] - 11s 10ms/step - loss: 1.7912 - acc: 0.1652\n",
      "Epoch 2/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7912 - acc: 0.1785\n",
      "Epoch 3/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7909 - acc: 0.1767\n",
      "Epoch 4/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7906 - acc: 0.1767\n",
      "Epoch 5/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7904 - acc: 0.1767\n",
      "Epoch 6/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7902 - acc: 0.1767\n",
      "Epoch 7/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7900 - acc: 0.1767\n",
      "Epoch 8/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7899 - acc: 0.1767\n",
      "Epoch 9/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7897 - acc: 0.1767\n",
      "Epoch 10/10\n",
      "1126/1126 [==============================] - 10s 9ms/step - loss: 1.7896 - acc: 0.1767\n",
      "564/564 [==============================] - 3s 5ms/step\n",
      "1126/1126 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 11s 10ms/step - loss: 1.6766 - acc: 0.2431\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.4561 - acc: 0.4224\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.3227 - acc: 0.4916\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.1684 - acc: 0.5661\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.1025 - acc: 0.5954\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.0037 - acc: 0.6318\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 0.9338 - acc: 0.6451\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 0.9344 - acc: 0.6522\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 0.9053 - acc: 0.6593\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 0.8253 - acc: 0.7001\n",
      "563/563 [==============================] - 3s 5ms/step\n",
      "1127/1127 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 11s 10ms/step - loss: 1.7940 - acc: 0.1571\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7915 - acc: 0.1775\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7914 - acc: 0.1775\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7911 - acc: 0.1775\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7911 - acc: 0.1775\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7910 - acc: 0.1775\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7908 - acc: 0.1775\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7909 - acc: 0.1775\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7907 - acc: 0.1775\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 10s 9ms/step - loss: 1.7907 - acc: 0.1775\n",
      "563/563 [==============================] - 3s 5ms/step\n",
      "1127/1127 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "1126/1126 [==============================] - 11s 10ms/step - loss: 1.7595 - acc: 0.1972\n",
      "Epoch 2/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.5777 - acc: 0.3410\n",
      "Epoch 3/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.4936 - acc: 0.4405\n",
      "Epoch 4/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.3670 - acc: 0.4787\n",
      "Epoch 5/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.2940 - acc: 0.5080\n",
      "Epoch 6/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.3206 - acc: 0.4849\n",
      "Epoch 7/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.2330 - acc: 0.5222\n",
      "Epoch 8/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.1453 - acc: 0.5710\n",
      "Epoch 9/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.0745 - acc: 0.6012\n",
      "Epoch 10/10\n",
      "1126/1126 [==============================] - 9s 8ms/step - loss: 1.0132 - acc: 0.6234\n",
      "564/564 [==============================] - 3s 5ms/step\n",
      "1126/1126 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 11s 10ms/step - loss: 1.7464 - acc: 0.2334\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.6426 - acc: 0.3416\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.4459 - acc: 0.4605\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.2974 - acc: 0.5182\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.1343 - acc: 0.5936\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.0709 - acc: 0.5963\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.0671 - acc: 0.5936\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.0101 - acc: 0.6122\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 0.9891 - acc: 0.6398\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 0.9007 - acc: 0.6735\n",
      "563/563 [==============================] - 3s 5ms/step\n",
      "1127/1127 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 11s 10ms/step - loss: 1.7421 - acc: 0.2644\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.6315 - acc: 0.3248\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.4985 - acc: 0.3886\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.4146 - acc: 0.4099\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.3841 - acc: 0.4561\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.3138 - acc: 0.5253\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.2433 - acc: 0.5271\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.1379 - acc: 0.5980\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.0548 - acc: 0.6131\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 9s 8ms/step - loss: 1.0315 - acc: 0.6140\n",
      "563/563 [==============================] - 3s 5ms/step\n",
      "1127/1127 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "1126/1126 [==============================] - 6s 6ms/step - loss: 1.7197 - acc: 0.2780\n",
      "Epoch 2/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.5906 - acc: 0.3428\n",
      "Epoch 3/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.4960 - acc: 0.3854\n",
      "Epoch 4/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.4081 - acc: 0.4281\n",
      "Epoch 5/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.3483 - acc: 0.4583\n",
      "Epoch 6/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.2947 - acc: 0.4787\n",
      "Epoch 7/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.3137 - acc: 0.4876\n",
      "Epoch 8/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.2690 - acc: 0.4982\n",
      "Epoch 9/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.1999 - acc: 0.5284\n",
      "Epoch 10/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.1404 - acc: 0.5728\n",
      "564/564 [==============================] - 1s 3ms/step\n",
      "1126/1126 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.7548 - acc: 0.2032\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.6242 - acc: 0.3194\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.5379 - acc: 0.3736\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.4640 - acc: 0.4153\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.4001 - acc: 0.4596\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.3353 - acc: 0.5333\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.2552 - acc: 0.5652\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.2479 - acc: 0.5608\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.1470 - acc: 0.5972\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.0940 - acc: 0.6078\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "1127/1127 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 6s 6ms/step - loss: 1.7914 - acc: 0.1668\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.7548 - acc: 0.2413\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.6401 - acc: 0.2990\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.6118 - acc: 0.2937\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.5373 - acc: 0.3425\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.4852 - acc: 0.3469\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.4279 - acc: 0.3425\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.3961 - acc: 0.3922\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.3695 - acc: 0.4232\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.3252 - acc: 0.4472\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "1127/1127 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "1690/1690 [==============================] - 16s 10ms/step - loss: 1.6779 - acc: 0.2503\n",
      "Epoch 2/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 1.5077 - acc: 0.3692\n",
      "Epoch 3/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 1.4332 - acc: 0.4343\n",
      "Epoch 4/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 1.3696 - acc: 0.4834\n",
      "Epoch 5/10\n",
      "1690/1690 [==============================] - 14s 8ms/step - loss: 1.2958 - acc: 0.5059\n",
      "Epoch 6/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 1.2291 - acc: 0.5408\n",
      "Epoch 7/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 1.1602 - acc: 0.5621\n",
      "Epoch 8/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 1.1175 - acc: 0.5787\n",
      "Epoch 9/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 1.0029 - acc: 0.6284\n",
      "Epoch 10/10\n",
      "1690/1690 [==============================] - 14s 9ms/step - loss: 0.9928 - acc: 0.6213\n",
      "0.501183432094\n",
      "{'kernel_size_two': (4, 4), 'kernel_size_one': (4, 4)}\n"
     ]
    }
   ],
   "source": [
    "cnn_model = KerasClassifier(build_fn=model_funk, verbose=1, input_shape=(64,64,3), epochs=10)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'kernel_size_one': [(4,4), (2,2)],\n",
    "    'kernel_size_two': [(4,4), (2,2)],\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(cnn_model, param_distributions=params, n_iter=3)\n",
    "rs.fit(X_train, y_train)\n",
    "print(rs.best_score_)\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_funk(input_shape=(64,64,3), layer_one_neurons=25, layer_two_neurons=20, \n",
    "               batch_size=50, max1=(4,4), max2=(4,4), dense1=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(layer_one_neurons, kernel_size=(4,4), input_shape=(64,64,3), activation='relu'))\n",
    "    model.add(Conv2D(layer_two_neurons, kernel_size=(4,4), activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(15, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.6995 - acc: 0.2575\n",
      "Epoch 2/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.5679 - acc: 0.3677\n",
      "Epoch 3/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.4894 - acc: 0.4361\n",
      "Epoch 4/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.4519 - acc: 0.4609\n",
      "Epoch 5/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.3897 - acc: 0.4849\n",
      "Epoch 6/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.3514 - acc: 0.4920\n",
      "Epoch 7/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.3607 - acc: 0.4831\n",
      "Epoch 8/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.2620 - acc: 0.5293\n",
      "Epoch 9/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.2107 - acc: 0.5631\n",
      "Epoch 10/10\n",
      "1126/1126 [==============================] - 5s 4ms/step - loss: 1.1827 - acc: 0.5764\n",
      "564/564 [==============================] - 1s 1ms/step\n",
      "1126/1126 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.7843 - acc: 0.2014\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.6942 - acc: 0.3159\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.5716 - acc: 0.3860\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.4241 - acc: 0.4579\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.3121 - acc: 0.4933\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.1999 - acc: 0.5226\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.1333 - acc: 0.5404\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.1000 - acc: 0.5705\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.1087 - acc: 0.5759\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.0009 - acc: 0.6051\n",
      "563/563 [==============================] - 1s 2ms/step\n",
      "1127/1127 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.7653 - acc: 0.1970\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.6424 - acc: 0.3132\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.4495 - acc: 0.4374\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.3012 - acc: 0.5359\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.2065 - acc: 0.5785\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.2058 - acc: 0.5714\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.1344 - acc: 0.6096\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.0545 - acc: 0.6193\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.0419 - acc: 0.6229\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 5s 4ms/step - loss: 1.0141 - acc: 0.6300\n",
      "563/563 [==============================] - 1s 2ms/step\n",
      "1127/1127 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.7895 - acc: 0.1758\n",
      "Epoch 2/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.7616 - acc: 0.2114\n",
      "Epoch 3/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.6823 - acc: 0.2726\n",
      "Epoch 4/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.6084 - acc: 0.3419\n",
      "Epoch 5/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.5254 - acc: 0.3961\n",
      "Epoch 6/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.4700 - acc: 0.4272\n",
      "Epoch 7/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.4344 - acc: 0.4307\n",
      "Epoch 8/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.4211 - acc: 0.4520\n",
      "Epoch 9/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.3555 - acc: 0.4778\n",
      "Epoch 10/10\n",
      "1126/1126 [==============================] - 6s 5ms/step - loss: 1.3245 - acc: 0.4956\n",
      "564/564 [==============================] - 1s 2ms/step\n",
      "1126/1126 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.7536 - acc: 0.2254\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.6265 - acc: 0.3052\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.5150 - acc: 0.4028\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.4223 - acc: 0.4410\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.2684 - acc: 0.5271\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.1705 - acc: 0.5697\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.1121 - acc: 0.5856\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.0347 - acc: 0.6114\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 0.9396 - acc: 0.6655\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 0.8800 - acc: 0.6894\n",
      "563/563 [==============================] - 1s 2ms/step\n",
      "1127/1127 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.7591 - acc: 0.2130\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.6842 - acc: 0.2724\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.6029 - acc: 0.3398\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.4653 - acc: 0.4561\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.4233 - acc: 0.4925\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.3688 - acc: 0.5120\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.3032 - acc: 0.5492\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.4086 - acc: 0.4933\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.2578 - acc: 0.5705\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 6s 5ms/step - loss: 1.2306 - acc: 0.5705\n",
      "563/563 [==============================] - 1s 2ms/step\n",
      "1127/1127 [==============================] - 2s 2ms/step\n",
      "Epoch 1/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 1.7061 - acc: 0.2815\n",
      "Epoch 2/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 1.5602 - acc: 0.3623\n",
      "Epoch 3/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 1.4975 - acc: 0.4147\n",
      "Epoch 4/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 1.2677 - acc: 0.5195\n",
      "Epoch 5/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 1.1485 - acc: 0.5524\n",
      "Epoch 6/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 1.0616 - acc: 0.6030\n",
      "Epoch 7/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 1.0346 - acc: 0.6110\n",
      "Epoch 8/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 0.9639 - acc: 0.6350\n",
      "Epoch 9/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 0.9075 - acc: 0.6385\n",
      "Epoch 10/10\n",
      "1126/1126 [==============================] - 8s 7ms/step - loss: 0.8899 - acc: 0.6741\n",
      "564/564 [==============================] - 2s 3ms/step\n",
      "1126/1126 [==============================] - 3s 3ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 8s 8ms/step - loss: 1.7550 - acc: 0.2493\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.5924 - acc: 0.3514\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.3937 - acc: 0.4374\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.2672 - acc: 0.4854\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.2121 - acc: 0.5280\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.1468 - acc: 0.5492\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.0453 - acc: 0.5865\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 0.9688 - acc: 0.6220\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 0.9245 - acc: 0.6504\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 0.8360 - acc: 0.6761\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "1127/1127 [==============================] - 3s 3ms/step\n",
      "Epoch 1/10\n",
      "1127/1127 [==============================] - 8s 8ms/step - loss: 1.7909 - acc: 0.1801\n",
      "Epoch 2/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.7305 - acc: 0.2671\n",
      "Epoch 3/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.6151 - acc: 0.2937\n",
      "Epoch 4/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.5248 - acc: 0.3390\n",
      "Epoch 5/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.4045 - acc: 0.4028\n",
      "Epoch 6/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.3889 - acc: 0.4516\n",
      "Epoch 7/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.2767 - acc: 0.5040\n",
      "Epoch 8/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.1978 - acc: 0.5705\n",
      "Epoch 9/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.1792 - acc: 0.5847\n",
      "Epoch 10/10\n",
      "1127/1127 [==============================] - 8s 7ms/step - loss: 1.1021 - acc: 0.6007\n",
      "563/563 [==============================] - 2s 3ms/step\n",
      "1127/1127 [==============================] - 3s 3ms/step\n",
      "Epoch 1/10\n",
      "1690/1690 [==============================] - 8s 5ms/step - loss: 1.7235 - acc: 0.2462\n",
      "Epoch 2/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.4825 - acc: 0.4036\n",
      "Epoch 3/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.2922 - acc: 0.4858\n",
      "Epoch 4/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.2430 - acc: 0.5183\n",
      "Epoch 5/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.1426 - acc: 0.5562\n",
      "Epoch 6/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.0580 - acc: 0.5964\n",
      "Epoch 7/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 1.0087 - acc: 0.6432\n",
      "Epoch 8/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.9610 - acc: 0.6479\n",
      "Epoch 9/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.9057 - acc: 0.6675\n",
      "Epoch 10/10\n",
      "1690/1690 [==============================] - 7s 4ms/step - loss: 0.8748 - acc: 0.6840\n",
      "0.566272188873\n",
      "{'layer_two_neurons': 20, 'layer_one_neurons': 12, 'dense1': 16}\n"
     ]
    }
   ],
   "source": [
    "cnn_model = KerasClassifier(build_fn=model_funk, verbose=1, input_shape=(64,64,3), epochs=10)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'dense1': [16,18,20,22,24],\n",
    "    'layer_one_neurons': [10,12,15,18],\n",
    "    'layer_two_neurons': [10,12,16,20,25,28],\n",
    "\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(cnn_model, param_distributions=params, n_iter=3)\n",
    "rs.fit(X_train, y_train)\n",
    "print(rs.best_score_)\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=(4,4), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(Conv2D(25, kernel_size=(4,4), activation='relu'))\n",
    "model.add(MaxPool2D((4,4)))\n",
    "model.add(Conv2D(15, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model testing params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=(4,4), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(Conv2D(20, kernel_size=(4,4), activation='relu'))\n",
    "model.add(Conv2D(15, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D((4,4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
